# Post-v0.9 Long-Term Roadmap Design (8-Day Sprint Edition)

Date: 2026-02-28  
Scope Window: 2026-03-30 to 2026-04-06 (8 days, Asia/Shanghai)

## 1. Why This Roadmap

The v0.9 delivery track is effective, but long-term quality still depends on three unresolved areas:

1. Architecture debt has known hotspots (`Circuit`, `Solver`, `ObservationPanel`) and needs scheduled cleanup.
2. Mobile KPI claims still rely too much on scripted interaction counts.
3. Evidence and release gates need stronger consistency controls (noise filtering and date/artifact integrity).
4. Component interaction behavior is powerful but discoverability is weak, and usage docs can drift from real behavior.

This sprint keeps those three areas as hard requirements, but compresses execution to 8 days.

## 2. Non-Negotiable Principles

1. Reliability first: no structural refactor can break `baseline:p0` or `baseline:circuitjs`.
2. Evidence first: each day ends with runnable command output + artifact path.
3. Single-source diagnostics: UI and AI must consume one canonical runtime diagnostics payload.
4. KPI validity: synthetic metrics and real interaction metrics must be reported separately.
5. Interaction-doc sync: any interaction behavior change must update usage guide in the same change set.

## 3. 8-Day Delivery Plan

### Day 1 (2026-03-30): Gate Hygiene and Evidence Integrity

Goal:
- Make quality gate signals trustworthy.

Tasks:
1. Exclude generated build outputs from lint scope.
2. Add CI checks for warning drift on critical jobs.
3. Add a doc consistency check for release date and artifact references.
4. Create a component interaction usage guide and wire it into CI sync checks.

Interaction guide baseline examples (must be documented):
- `Alt + 拖动端子`: 伸长/缩短元器件引脚
- `Ctrl/Cmd + 点击导线`: 分割导线端点

Exit criteria:
1. `npm run check:full` passes without generated-file lint noise.
2. CI gate output is stable in repeated runs.
3. Interaction usage guide exists and sync checks pass.

### Day 2 (2026-03-31): Runtime Diagnostics Unification

Goal:
- Remove duplicate diagnostics construction paths.

Tasks:
1. Keep diagnostics generation in one canonical circuit/runtime path.
2. Remove recomputation/overwrite in app update flow.
3. Add contract tests for `code/categories/summary/hints/componentIds/wireIds/fatal`.

Exit criteria:
1. UI and AI consume the same diagnostics contract from one producer path.
2. Diagnostics regression tests all pass.

### Day 3 (2026-04-01): Registry Coverage Mapping + Refactor Slice A

Goal:
- Turn component behavior ownership into explicit matrix.

Tasks:
1. Produce supported-type vs registry-handler matrix.
2. Migrate high-frequency passive/device types into registry-first path.
3. Add completeness tests for registered handlers.

Exit criteria:
1. New behavior for covered types does not require direct solver switch edits.
2. Solver/regression subset stays green.

### Day 4 (2026-04-02): Refactor Slice B + NetlistBuilder First Real Use

Goal:
- Reduce solver coupling surface.

Tasks:
1. Migrate one end-to-end solve path through meaningful `NetlistBuilder` DTO (not pass-through).
2. Add netlist contract tests and compatibility assertions.
3. Preserve existing solve output contract.

Exit criteria:
1. At least one production solve flow uses netlist DTO path.
2. `npm test` + `npm run baseline:p0` pass.

### Day 5 (2026-04-03): Mobile KPI Validity Upgrade

Goal:
- Make mobile KPI decision-grade.

Tasks:
1. Label current tap-count baseline as synthetic metric.
2. Add real interaction telemetry counters:
   - task success funnel
   - cancellation rate for destructive touch actions
   - task median/p90 completion time
3. Define denominator and sampling rules in docs.

Exit criteria:
1. Synthetic vs real metrics appear side by side.
2. Mobile KPI claim rules become auditable.

### Day 6 (2026-04-04): Observation Performance Hardening

Goal:
- Prevent performance regressions while keeping observation features.

Tasks:
1. Add large-buffer stress checks for linked cursor and auto-range.
2. Add frame-time smoke checks to observation E2E.
3. Add export integrity checks (PNG payload + metadata consistency).

Exit criteria:
1. Observation stress checks report no blocker-level regressions.
2. Observation E2E remains green with integrity artifacts.

### Day 7 (2026-04-05): AI Teaching Reliability Tightening

Goal:
- Improve deterministic quality of "what/why/how to fix" outputs.

Tasks:
1. Expand diagnostic-to-lesson mapping and conflict resolution rules.
2. Add deterministic mini-eval set for classroom failure categories.
3. Add fallback policy tests for missing/invalid diagnostics.

Exit criteria:
1. Canonical runtime failure categories produce consistent teaching guidance.
2. AI eval baseline remains stable or improves with documented diff.

### Day 8 (2026-04-06): v1.0 Readiness Gate (Sprint Closure)

Goal:
- Convert sprint results into release governance artifacts.

Tasks:
1. Run full gate (`check:full` and scoped E2E suites).
2. Publish go/no-go matrix with blockers and residual risks.
3. Freeze scope and open ranked post-sprint backlog.

Exit criteria:
1. All required gates pass on candidate snapshot.
2. Quality/mobile/observation/AI each have signed evidence and artifact links.

## 4. Metrics and Reporting Rules

Report two metric tiers every day:

1. Engineering synthetic metrics
- `check:full` pass/fail
- baseline drift count (`p0`, `circuitjs`, `ai`)
- E2E pass/fail and artifact completeness

2. Product behavior metrics
- mobile task completion median/p90
- mis-touch prevention effectiveness
- observation latency envelope
- diagnostic hint-to-repair conversion (pilot-ready format)

Hard rule:
- No UX KPI success claim can be made from synthetic metrics alone.

## 5. Risk Controls

1. Refactor scope control:
- No feature expansion on Day 3 and Day 4.

2. Regression control:
- Any baseline red blocks merge unless waived with documented risk.

3. Evidence control:
- Each day must record commands, results, artifact paths, and residual risks.

4. Ownership control:
- Each track has one owner and one backup reviewer.

5. Interaction-change control:
- Any PR that changes interaction keybinding/gesture logic must update the interaction usage guide and pass sync tests.

## 6. Definition of Success

The 8-day sprint is successful only if all are true:

1. Architecture debt items land as test-backed changes, not TODOs.
2. KPI statements are backed by valid metric definitions and artifacts.
3. Final readiness decision is reproducible from command outputs and linked evidence.
